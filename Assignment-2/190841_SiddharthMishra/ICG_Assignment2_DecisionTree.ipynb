{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "DTImplementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgLIEjcYUtaJ"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "#print(train_data[\"Age\"].isnull().sum())\n",
        "\n",
        "#mod_train_data = train_data.dropna(subset=['Age'])\n",
        "mod_train_data = train_data\n",
        "tr_med = mod_train_data['Age'].median(skipna=True);\n",
        "#print(\"median \",tr_med)\n",
        "mod_train_data.fillna(tr_med,inplace=True)\n",
        "mod_train_data['Sex'].replace(['male','female'],[1,2],inplace=True)\n",
        "\n",
        "mod_test_data = test_data\n",
        "ts_med = mod_test_data['Age'].median(skipna=True);\n",
        "#print(\"median \",ts_med)\n",
        "mod_test_data.fillna(ts_med,inplace=True)\n",
        "mod_test_data['Sex'].replace(['male','female'],[1,2],inplace=True)\n",
        "\n",
        "mod_train_data.to_csv('mod_train_data.csv',index=False)\n",
        "mod_test_data.to_csv('mod_test_data.csv',index=False)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkWXLxojUtaO"
      },
      "source": [
        "X_train, y_train = mod_train_data.drop(columns = 'Survived'), mod_train_data['Survived']\n",
        "X_val, y_val = mod_test_data.drop(columns = 'Survived'), mod_test_data['Survived']\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iY78gkaUtaO"
      },
      "source": [
        "class Node:\n",
        "    def __init__(self):\n",
        "        \n",
        "        # links to the left and right child nodes\n",
        "        self.right = None\n",
        "        self.left = None\n",
        "        \n",
        "        # derived from splitting criteria\n",
        "        self.column = None\n",
        "        self.threshold = None\n",
        "        \n",
        "        # probability for object inside the Node to belong for each of the given classes\n",
        "        self.probas = None\n",
        "        # depth of the given node\n",
        "        self.depth = None\n",
        "        \n",
        "        # if it is the root Node or not\n",
        "        self.is_terminal = False"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx3tROoFUtaP"
      },
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth = 3, min_samples_leaf = 1, min_samples_split = 2):\n",
        "        \n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.min_samples_split = min_samples_split\n",
        "        \n",
        "        self.classes = None\n",
        "        \n",
        "        # Decision tree itself\n",
        "        self.Tree = None\n",
        "    \n",
        "    def nodeProbas(self, y):\n",
        "        '''\n",
        "        Calculates probability of class in a given node\n",
        "        '''\n",
        "        \n",
        "        probas = []\n",
        "        \n",
        "        # for each unique label calculate the probability for it\n",
        "        for one_class in self.classes:\n",
        "            proba = y[y == one_class].shape[0] / y.shape[0]\n",
        "            probas.append(proba)\n",
        "        return np.asarray(probas)\n",
        "\n",
        "    def gini(self, probas):\n",
        "        '''\n",
        "        Calculates gini criterion\n",
        "        '''\n",
        "        \n",
        "        return 1 - np.sum(probas**2)\n",
        "    \n",
        "    def calcImpurity(self, y):\n",
        "        return self.gini(self.nodeProbas(y))\n",
        "    \n",
        "    def calcBestSplit(self, X, y):\n",
        "        '''\n",
        "        Calculates the best possible split for the internal node of the tree\n",
        "        '''\n",
        "        \n",
        "        bestSplitCol = None\n",
        "        bestThresh = None\n",
        "        bestInfoGain = -999\n",
        "        \n",
        "        impurityBefore = self.calcImpurity(y)\n",
        "        \n",
        "        # for each column in X\n",
        "        for col in range(X.shape[1]):\n",
        "            x_col = X[:, col]\n",
        "            \n",
        "            # for each value in the column\n",
        "            for x_i in x_col:\n",
        "                threshold = x_i\n",
        "                y_right = y[x_col > threshold]\n",
        "                y_left = y[x_col <= threshold]\n",
        "                \n",
        "                if y_right.shape[0] == 0 or y_left.shape[0] == 0:\n",
        "                    continue\n",
        "                    \n",
        "                # calculate impurity for the right and left nodes\n",
        "                impurityRight = self.calcImpurity(y_right)\n",
        "                impurityLeft = self.calcImpurity(y_left)\n",
        "                \n",
        "                # calculate information gain\n",
        "                infoGain = impurityBefore\n",
        "                infoGain -= (impurityLeft * y_left.shape[0] / y.shape[0]) + (impurityRight * y_right.shape[0] / y.shape[0])\n",
        "                \n",
        "                # is this infoGain better then all other?\n",
        "                if infoGain > bestInfoGain:\n",
        "                    bestSplitCol = col\n",
        "                    bestThresh = threshold\n",
        "                    bestInfoGain = infoGain\n",
        "                    \n",
        "        \n",
        "        # if we still didn't find the split\n",
        "        if bestInfoGain == -999:\n",
        "            return None, None, None, None, None, None\n",
        "        \n",
        "        # making the best split\n",
        "        \n",
        "        x_col = X[:, bestSplitCol]\n",
        "        x_left, x_right = X[x_col <= bestThresh, :], X[x_col > bestThresh, :]\n",
        "        y_left, y_right = y[x_col <= bestThresh], y[x_col > bestThresh]\n",
        "        \n",
        "        return bestSplitCol, bestThresh, x_left, y_left, x_right, y_right\n",
        "                \n",
        "                \n",
        "                \n",
        "    \n",
        "    def buildDT(self, X, y, node):\n",
        "        '''\n",
        "        Recursively builds decision tree from the top to bottom\n",
        "        '''\n",
        "        \n",
        "        # checking for the terminal conditions\n",
        "        \n",
        "        if node.depth >= self.max_depth:\n",
        "            node.is_terminal = True\n",
        "            return\n",
        "        \n",
        "        if X.shape[0] < self.min_samples_split:\n",
        "            node.is_terminal = True\n",
        "            return\n",
        "        \n",
        "        if np.unique(y).shape[0] == 1:\n",
        "            node.is_terminal = True\n",
        "            return\n",
        "        \n",
        "        # calculating current split\n",
        "        splitCol, thresh, x_left, y_left, x_right, y_right = self.calcBestSplit(X, y)\n",
        "        \n",
        "        #Leaf node has no splitting feature\n",
        "        if splitCol is None:    \n",
        "            node.is_terminal = True\n",
        "\n",
        "        #Leaf nodes can also have too less samples    \n",
        "        if x_left.shape[0] < self.min_samples_leaf or x_right.shape[0] < self.min_samples_leaf: \n",
        "            node.is_terminal = True\n",
        "            return\n",
        "        \n",
        "        node.column = splitCol\n",
        "        node.threshold = thresh\n",
        "        \n",
        "        # creating left and right child nodes\n",
        "        node.left = Node()\n",
        "        node.left.depth = node.depth + 1\n",
        "        node.left.probas = self.nodeProbas(y_left)\n",
        "        \n",
        "        node.right = Node()\n",
        "        node.right.depth = node.depth + 1\n",
        "        node.right.probas = self.nodeProbas(y_right)\n",
        "        \n",
        "        # splitting recursively\n",
        "        self.buildDT(x_right, y_right, node.right)\n",
        "        self.buildDT(x_left, y_left, node.left)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Fitting the training data to model\n",
        "        '''\n",
        "        \n",
        "        if type(X) == pd.DataFrame:\n",
        "            X = np.asarray(X)\n",
        "        \n",
        "        self.classes = np.unique(y)\n",
        "        # root node creation\n",
        "        self.Tree = Node()\n",
        "        self.Tree.depth = 1\n",
        "        self.Tree.probas = self.nodeProbas(y)\n",
        "        \n",
        "        self.buildDT(X, y, self.Tree)\n",
        "    \n",
        "    def predictSample(self, x, node):\n",
        "        '''\n",
        "        Passes one object through decision tree and return the probability of it to belong to each class\n",
        "        '''\n",
        "       \n",
        "    \n",
        "        # if we have reached the terminal node of the tree\n",
        "        if node.is_terminal:\n",
        "            return node.probas\n",
        "        \n",
        "        if x[node.column] > node.threshold:\n",
        "            probas = self.predictSample(x, node.right)\n",
        "        else:\n",
        "            probas = self.predictSample(x, node.left)\n",
        "            \n",
        "        return probas\n",
        "        \n",
        "        \n",
        "    \n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Returns the labels for each X\n",
        "        '''\n",
        "        \n",
        "        if type(X) == pd.DataFrame:\n",
        "            X = np.asarray(X)\n",
        "            \n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            pred = np.argmax(self.predictSample(x, self.Tree))\n",
        "            predictions.append(pred)\n",
        "        \n",
        "        return np.asarray(predictions)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGRIj2WSUtaR",
        "outputId": "d38200dd-70cb-4254-bef4-bf90d314e9d6"
      },
      "source": [
        "model = DecisionTreeClassifier(max_depth = 10, min_samples_leaf=2, min_samples_split=2)\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 28.4 s, sys: 88.3 ms, total: 28.5 s\n",
            "Wall time: 28.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61vbSWuJUtaR",
        "outputId": "d90a68f8-e9ca-4e4c-c69e-0dee603bb019"
      },
      "source": [
        "def F1(y_pred, y_val):\n",
        "  tp = fp = tn = fn = 0\n",
        "  for i in range(len(y_val)):\n",
        "    if (y_pred[i]==1 and y_val[i]==1):\n",
        "      tp+=1\n",
        "    elif (y_pred[i]==1 and y_val[i]==0):\n",
        "      fp+=1\n",
        "    elif (y_pred[i]==0 and y_val[i]==1):\n",
        "      fn+=1\n",
        "    else:\n",
        "      tn +=1\n",
        "  prec = float(tp)/float(tp+fp)   #precision\n",
        "  rec = float(tp)/float(tp+fn)    #recall\n",
        "  f1 = 2*float(prec)*float(rec)/float(prec+rec)\n",
        "  return f1\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "test_score = float(sum(y_pred == y_val))/ float(len(y_val))\n",
        "test_loss = int(sum(y_pred != y_val))\n",
        "train_score = float(sum(model.predict(X_train) == y_train))/ float(len(y_train))\n",
        "train_loss = int(sum(model.predict(X_train) != y_train))\n",
        "print(\"Training Accuracy is \", train_score)\n",
        "print(\"Test Accuracy is \", test_score)\n",
        "print(\"Training Loss is \", train_loss)\n",
        "print(\"Testing Loss is \", test_loss)\n",
        "\n",
        "train_f1 = F1(model.predict(X_train),y_train)\n",
        "print(\"Training F1 score is \", train_f1)\n",
        "test_f1 = F1(y_pred,y_val)\n",
        "print(\"Testing F1 score is \", test_f1)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy is  0.8870967741935484\n",
            "Test Accuracy is  0.8265682656826568\n",
            "Training Loss is  70\n",
            "Testing Loss is  47\n",
            "Training F1 score is  0.8444444444444443\n",
            "Testing F1 score is  0.7539267015706805\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}