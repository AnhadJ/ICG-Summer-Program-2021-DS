{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(src):\n",
    "    df = pd.read_csv(src)\n",
    "\n",
    "    df=df.replace(to_replace=\"male\",value=0)\n",
    "    df=df.replace(to_replace=\"female\",value=1)\n",
    "\n",
    "    mean = df['Age'].mean()\n",
    "    df.fillna(mean, inplace = True)\n",
    "    df = df.drop(columns=['PassengerId'])\n",
    "    df.columns = ['output', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch','Fare']\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   output  Pclass  Sex   Age  SibSp  Parch     Fare\n0       0       3    0  22.0      1      0   7.2500\n1       1       1    1  38.0      1      0  71.2833\n2       1       3    1  26.0      0      0   7.9250\n3       1       1    1  35.0      1      0  53.1000\n4       0       3    0  35.0      0      0   8.0500\n   output  Pclass  Sex   Age  SibSp  Parch     Fare\n0       0       3    0  27.0      1      0  14.4542\n1       1       1    0  42.0      1      0  52.5542\n2       1       3    0  20.0      1      1  15.7417\n3       0       3    0  21.0      0      0   7.8542\n4       0       3    0  21.0      0      0  16.1000\n"
     ]
    }
   ],
   "source": [
    "train_df = load_csv(\"../data/train.csv\")\n",
    "test_df = load_csv('../data/test.csv')"
   ]
  },
  {
   "source": [
    "# Entropy of a column\n",
    "def entropy(column):\n",
    "    # count of each unique values (class) of a column\n",
    "    counts = np.unique(column, return_counts=True)\n",
    "    sum = 0.0\n",
    "    for i in counts[1]:\n",
    "        # Probability of a class\n",
    "        prob = i/column.shape[0]\n",
    "        sum+= (-1.0 * prob * np.log2(prob))\n",
    "    return sum"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data(x_data, title_name, mean_val):\n",
    "    # x_right is dataframe for the right node, which will be used further\n",
    "    x_right = pd.DataFrame([],columns = x_data.columns)\n",
    "    # x_left is dataframe for the right node, which will be used further\n",
    "    x_left = pd.DataFrame([],columns = x_data.columns)\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # title_name - key column on basis of which data will be divided\n",
    "        val = x_data[title_name].loc[i]\n",
    "        if val >= mean_val:\n",
    "            x_right = x_right.append(x_data.iloc[i])\n",
    "        else:\n",
    "            x_left = x_left.append(x_data.iloc[i])\n",
    "    return x_right, x_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info gain of a class\n",
    "def info_gain(x_data, title_name, mean_val):\n",
    "    right, left = divide_data(x_data, title_name, mean_val)\n",
    "\n",
    "    # l and r are prob. of the classes\n",
    "    l = float(left.shape[0])/x_data.shape[0]\n",
    "    r = float(right.shape[0])/x_data.shape[0]\n",
    "    # If data is totally pure (every value is same)\n",
    "    if left.shape[0] == 0 or right.shape[0] == 0:\n",
    "        return -99999\n",
    "    gain = entropy(x_data.output) - (l * entropy(left.output) + r * entropy(right.output))\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, depth=0, max_depth=5):\n",
    "        # Left Node\n",
    "        self.left = None\n",
    "        # Right Node\n",
    "        self.right = None\n",
    "        self.title_name = None\n",
    "        self.mean_val = None\n",
    "        self.depth = depth\n",
    "        self.max_depth = max_depth\n",
    "        # Output value\n",
    "        self.target = None\n",
    "    def train_modal(self, x_train):\n",
    "        features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "        info_gains = []\n",
    "        # Informatio gain for all features\n",
    "        for i in features:\n",
    "            i_gain = info_gain(x_train, i, x_train[i].mean())\n",
    "            info_gains.append(i_gain)\n",
    "        # title_name - title name of highest info gain feature\n",
    "        self.title_name = features[np.argmax(info_gains)]\n",
    "        # Value on basis of which data will be splitted\n",
    "        # > mean_val will go to right node and < mean_val to left node\n",
    "        self.mean_val = x_train[self.title_name].mean()\n",
    "        # Splitting Tree \n",
    "        data_right, data_left = divide_data(x_train, self.title_name, self.mean_val)\n",
    "        data_right = data_right.reset_index(drop=True)\n",
    "        data_left = data_left.reset_index(drop=True)\n",
    "        # Setting Leaf Nodes\n",
    "        if data_left.shape[0] == 0 or data_right.shape[0] == 0:\n",
    "            if x_train.output.mean() >= 0.5:\n",
    "                self.target = 1\n",
    "            else:\n",
    "                self.target = 0\n",
    "            return\n",
    "        if self.depth >= self.max_depth:\n",
    "            if x_train.output.mean() >= 0.5:\n",
    "                self.target = 1\n",
    "            else:\n",
    "                self.target = 0\n",
    "            return\n",
    "\n",
    "        self.left = DecisionTree(self.depth+1, self.max_depth)\n",
    "        self.left.train_modal(data_left)\n",
    "        self.right = DecisionTree(self.depth+1, self.max_depth)\n",
    "        self.right.train_modal(data_right)\n",
    "\n",
    "        if x_train.output.mean() >= 0.5:\n",
    "            self.target = 1\n",
    "        else:\n",
    "            self.target = 0\n",
    "        return\n",
    "        # Prediction\n",
    "    def predict(self, test):\n",
    "        if test[self.title_name] > self.mean_val:\n",
    "            if self.right is None:\n",
    "                return self.target\n",
    "            return self.right.predict(test)\n",
    "        if test[self.title_name] < self.mean_val:\n",
    "            if self.left is None:\n",
    "                return self.target\n",
    "            return self.left.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tree Data Structure\n",
    "dt = DecisionTree()\n",
    "dt.train_modal(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find Accuracy, loss and f1_score\n",
    "def acc(y_pred, y_test):\n",
    "  acuracy = 0\n",
    "  loss = 0\n",
    "  # True positive,\n",
    "  falsen = 0;truep = 0;falsep = 0;truen = 0;accuracy = 0\n",
    "  for i,j in zip(y_pred, y_test):\n",
    "    loss = loss + abs(i-j)\n",
    "    if i == j:\n",
    "      accuracy+=1\n",
    "    if i == 1 and j == 1:\n",
    "      truep+=1\n",
    "    elif i == 1 and j == 0:\n",
    "      falsep+=1\n",
    "    elif i==0 and j == 1:\n",
    "      falsen+=1\n",
    "    else:\n",
    "      truen+=1\n",
    "\n",
    "  recall = truep/(truep+falsen)\n",
    "  precision = truep/(truep + falsep)\n",
    "  f1_score = 2*precision*recall/(precision+recall)\n",
    "\n",
    "  print('Accuracy = ',accuracy/y_pred.shape[0])\n",
    "  print('Loss = ',loss)\n",
    "  print('F1_Score = ',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.8306451612903226\nLoss =  105\nF1_Score =  0.7712418300653595\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for train data\n",
    "y_pred=[]\n",
    "for i in range(train_df.shape[0]):\n",
    "    pred = dt.predict(train_df.loc[i])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "acc(y_pred, np.array(train_df['output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy =  0.8302583025830258\nLoss =  46\nF1_Score =  0.7386363636363636\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for test data\n",
    "y_pred = []\n",
    "for i in range(test_df.shape[0]):\n",
    "    pred = dt.predict(test_df.loc[i])\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "# type(test_df['output'])\n",
    "acc(y_pred, np.array(test_df['output']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "50af46669fc1fbf4a481a8ca2944115fd3a2e5a871b7b13ed20079dadcd15667"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
